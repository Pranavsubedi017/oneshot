# -*- coding: utf-8 -*-
"""image_recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nxK71iHuHUi2wFTpSxyDcGldmAdm0ihS
"""

import sys
sys.path.append('/content/drive/My Drive/')
import conv2d
import numpy as np
import dense
import network
from sklearn.datasets import fetch_lfw_people
from sklearn.model_selection import train_test_split

class OneShot():
  def load_data(self,no_of_person):

      lfw_people = fetch_lfw_people(min_faces_per_person=no_of_person, resize=0.4)    #user can load their own data and call create pairs
      X = lfw_people.images
      y = lfw_people.target

      X = X / 255.0
      X = np.expand_dims(X, axis=-1)

      return X, y, lfw_people.target_names

  def create_pairs(self,X, y):
    pairs=[]
    labels=[]
    num_classes=len(np.unique(y))
    same_indices=[np.where(y==i[0]) for i in range (num_classes)]

    for i in range(len(X)):
      x1=X[i]
      y1=y[i]
      i2=np.random.choice(same_indices[y1])

      x2=X[i2]
      pairs+=[[x1,x2]]
      labels.append(1)

      y2 = (y1 + np.random.randint(1, num_classes)) % num_classes
      i2=np.random.choice(same_indices[y2])
      x2=X[i2]
      pairs+=[[x1,x2]]
      labels.append(0)

    return np.array(pairs), np.array(labels)

  def make_data(self,X,y):
    pairs_train, pairs_test, labels_train, labels_test = train_test_split(pairs, labels, test_size=0.2, random_state=42)
    return pairs_train, pairs_test, labels_train, labels_test

  def build_model():
    def make_model(self):

      nn=NeuralNetwork()
      nn.add(Convolve(Relu(), pooling=MaxPool((2,2)) , filter_size=(10,10),num_filters=64,stride=1,padding=1))
      nn.add(Convolve(Relu(), pooling=MaxPool((2,2)) , filter_size=(7,7),num_filters=128,stride=1,padding=1))
      nn.add(Convolve(Relu(), pooling=MaxPool((2,2)) , filter_size=(4,4),num_filters=128,stride=1,padding=1))
      nn.add(Convolve(Relu(), pooling=MaxPool((2,2)) , filter_size=(4,4),num_filters=256,stride=1,padding=1))
      nn.add(Flatten())
      nn.add(Dense(4096,4096,Sigmoid()))

    model=make_model()
    loss_function='contrastive_loss'
    optimizer='adam'
    learning_rate=0.001
    nn2=NeuralNetwork(loss_function,optimizer,learning_rate)
    nn2.add(model)
    nn2.add(model)

  def fit(self, X_train, y_train,X_test,y_test, batch_size=30,epochs=10):
    self.epochs=epochs
    for epoch in range(self.epochs):
        epoch_loss = 0
        epoch_loss_val = 0
        for i in range(0, len(X_train), batch_size):
            batch_inputs = X_train[i:i + batch_size]
            batch_validate=X_test[i:i + batch_size]
            batch_true_outputs = y_train[i:i + batch_size]
            batch_validate_outputs = y_test[i:i + batch_size]

            x = batch_inputs
            #print(f'x ko shape{x.shape}')
            for layer in self.layers:
                x = layer.forward(x)
                #print(x.shape)


            loss = self.loss_function.forward(x, batch_true_outputs, self.layers)
            epoch_loss += loss  # Accumulate batch loss

            gradient = self.loss_function.backward(x, batch_true_outputs)
            for layer in reversed(self.layers):
                # print(f'gradient is {gradient.shape}')
                gradient = layer.backward(gradient)
                # print(f'gradient is {gradient.shape}')

            for layer in self.layers:
                layer.calculate(self.optimizer)

            for layer in self.layers:
                layer.update(self.learning_rate, self.optimizer)


        print(f"Epoch {epoch + 1}, Loss: {epoch_loss / len(X_train) * batch_size}")  # Print average loss for the epoch
        epoch_accuracy = 0
        epoch_loss_val = 0
        # for i in range(0,len(X_test),batch_size):
        #     batch_validate = X_test[i:i + batch_size]
        #     batch_validate_true = y_test[i:i + batch_size]

        x2=X_test
        for layer in self.layers:
            x2=layer.forward(x2)

        loss_validate = self.loss_function.forward(x2, y_test, self.layers)
        accurate=self.loss_function.accuracy(x2, y_test)
        epoch_loss_val += loss_validate
        epoch_accuracy+=accurate
        print(f"Epoch {epoch + 1}, val_Loss: {epoch_loss_val},val_accuracy:{epoch_accuracy}")

